{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8b12be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>In-Reply-To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>office@ziegler-cat.com</td>\n",
       "      <td>01.10.2001  09:15:00</td>\n",
       "      <td>15779.1995312335.JavaMail.evans@thyme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Application for an Internship in Summer 2022</td>\n",
       "      <td>Dear sir or madam,\\n\\nI hereby want to apply f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>05.10.2021  11:01:00</td>\n",
       "      <td>78445.176352.JavaMail@ziegler</td>\n",
       "      <td>15779.1995312335.JavaMail.evans@thyme</td>\n",
       "      <td>Re: Application for an Internship in Summer 2022</td>\n",
       "      <td>Dear Mister Mayer,\\n\\nthank you a lot for your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>12.10.2021  23:11:00</td>\n",
       "      <td>784338.1763212.JavaMail@ziegler</td>\n",
       "      <td>78445.176352.JavaMail@ziegler</td>\n",
       "      <td>Re:Re: Application for an Internship in Summer...</td>\n",
       "      <td>Dear Mister Mayer,\\n\\nthank you for your appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>12.10.2021  08:05:00</td>\n",
       "      <td>127791.19953167485.JavaMail.evans@thyme</td>\n",
       "      <td>784338.1763212.JavaMail@ziegler</td>\n",
       "      <td>Re:Re:Re: Application for an Internship in Sum...</td>\n",
       "      <td>Dear Ms. Parker,\\n\\nthank you for your reply a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>jmayer94@gmail.com, g.sullenberger@ziegler-cat...</td>\n",
       "      <td>13.10.2021  09:33:00</td>\n",
       "      <td>784971.1786612.JavaMail@ziegler</td>\n",
       "      <td>127791.19953167485.JavaMail.evans@thyme</td>\n",
       "      <td>Invitation for Personal Meeting</td>\n",
       "      <td>Dear Mister Mayer,\\n\\nWe are happy to hear tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       From  \\\n",
       "0        jmayer94@gmail.com   \n",
       "1  j.parker@ziegler-cat.com   \n",
       "2  j.parker@ziegler-cat.com   \n",
       "3        jmayer94@gmail.com   \n",
       "4  j.parker@ziegler-cat.com   \n",
       "\n",
       "                                                  To              Datetime  \\\n",
       "0                             office@ziegler-cat.com  01.10.2001  09:15:00   \n",
       "1                                 jmayer94@gmail.com  05.10.2021  11:01:00   \n",
       "2                                 jmayer94@gmail.com  12.10.2021  23:11:00   \n",
       "3                           j.parker@ziegler-cat.com  12.10.2021  08:05:00   \n",
       "4  jmayer94@gmail.com, g.sullenberger@ziegler-cat...  13.10.2021  09:33:00   \n",
       "\n",
       "                                Message-ID  \\\n",
       "0    15779.1995312335.JavaMail.evans@thyme   \n",
       "1            78445.176352.JavaMail@ziegler   \n",
       "2          784338.1763212.JavaMail@ziegler   \n",
       "3  127791.19953167485.JavaMail.evans@thyme   \n",
       "4          784971.1786612.JavaMail@ziegler   \n",
       "\n",
       "                               In-Reply-To  \\\n",
       "0                                      NaN   \n",
       "1    15779.1995312335.JavaMail.evans@thyme   \n",
       "2            78445.176352.JavaMail@ziegler   \n",
       "3          784338.1763212.JavaMail@ziegler   \n",
       "4  127791.19953167485.JavaMail.evans@thyme   \n",
       "\n",
       "                                             Subject  \\\n",
       "0       Application for an Internship in Summer 2022   \n",
       "1   Re: Application for an Internship in Summer 2022   \n",
       "2  Re:Re: Application for an Internship in Summer...   \n",
       "3  Re:Re:Re: Application for an Internship in Sum...   \n",
       "4                    Invitation for Personal Meeting   \n",
       "\n",
       "                                             Content  \n",
       "0  Dear sir or madam,\\n\\nI hereby want to apply f...  \n",
       "1  Dear Mister Mayer,\\n\\nthank you a lot for your...  \n",
       "2  Dear Mister Mayer,\\n\\nthank you for your appli...  \n",
       "3  Dear Ms. Parker,\\n\\nthank you for your reply a...  \n",
       "4  Dear Mister Mayer,\\n\\nWe are happy to hear tha...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the main executablefile of the process mining pipeline\n",
    "# Author: Florian Lietz\n",
    "# Last edited\n",
    "# \n",
    "\n",
    "import os, sys, re\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "from stages.utils.utils import parseArgs, DataCleaner\n",
    "import spacy\n",
    "f = r\"C:\\Users\\flietz\\OneDrive - TU Wien\\!Studium\\1_MSc\\!Diplomarbeit\\code\\pipeline\\resources\\dataset\\Mail_ApplicationDummy.csv\"\n",
    "# import CSV file\n",
    "inputFile = pd.read_csv(f, delimiter=\";\")\n",
    "inputFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c865ffca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = inputFile.iloc[3,:][\"Content\"]\n",
    "temp\n",
    "pd.isnull(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6db7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUrl(content):\n",
    "    return re.sub(r'https?://\\S+', '', content)\n",
    "\n",
    "def removeMultWhitespace(content):\n",
    "    return re.sub(r' +', ' ', content)\n",
    "\n",
    "def stripEndClauses(content, clauses):\n",
    "    clauseIndex = 0\n",
    "    index = 0\n",
    "    # Find lowest greetings or end clause index and strip off everything that comes after it\n",
    "    for item in clauses:\n",
    "        # needle and haystack both in lowercase to ignore case\n",
    "        index = content.lower().find(item.lower())\n",
    "        if index > -1 and (index < clauseIndex or clauseIndex == 0):\n",
    "            clauseIndex = index\n",
    "    if clauseIndex > 0:\n",
    "        return content[:clauseIndex]\n",
    "    else:\n",
    "        return content\n",
    "\n",
    "def stripStartClauses(content, clauses):\n",
    "    clauseIndex = 0\n",
    "    index = 0\n",
    "    # Find lowest greetings or end clause index and strip off everything that comes after it\n",
    "    for item in clauses:\n",
    "        # needle and haystack both in lowercase to ignore case\n",
    "        index = content.lower().find(item.lower())\n",
    "        if index > -1 and (index > clauseIndex or clauseIndex == 0):\n",
    "            clauseIndex = index\n",
    "    if clauseIndex > 0:\n",
    "        return content[clauseIndex:]\n",
    "    else:\n",
    "        return content\n",
    "    \n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: removeMultWhitespace(row[\"Content\"]), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: removeUrl(row[\"Content\"]), axis=1)\n",
    "\n",
    "# Stripping of greeting phrases and end clauses\n",
    "startClausesList = [\"Dear sir or madam\", \"To whom it may concern\", \"Hello,\", \",\\n\\n\"]\n",
    "\n",
    "endGreetingsList = [\"Yours sincerely\", \"Sincerely\", \"Sincerely yours\", \"Take care\", \"Regards\",\n",
    "                 \"Warm regards\", \"Best regards\", \"Kind regards\", \"Warmest regards\", \"Yours truly\", \"Yours,\",\n",
    "                 \"Warmly,\", \"Warm wishes\", \"Best,\", \"Best Wishes\", \"Thanks in advance\", \"Thank you in advance\",\n",
    "                 \"Thanks in advance\", \"Thanks,\\n\", \"I am looking forward to hearing\", \"I'm looking forward to hearing\",\n",
    "                 \"I look forward to hearing from you\"]\n",
    "\n",
    "confList = [\"The information contained in this communication\",\n",
    "               \"The content of this email is confidential\", \"The content of this e-mail\", \"This email and attachments (if any) is intended\",\n",
    "               \"This email is intended solely\", \"This e-mail is intended\"]\n",
    "\n",
    "endClausesList = endGreetingsList+confList\n",
    "\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: stripEndClauses(row[\"Content\"], endClausesList), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: stripStartClauses(row[\"Content\"], startClausesList), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: re.sub(r'\\n+', '\\n', row[\"Content\"]), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: re.sub(r'\\n', ' ', row[\"Content\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea29ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89a6fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', thank you for your reply and for your kind invitation. The proposed date for a personal meeting works fine for me. I am looking forward to meeting you! '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = inputFile.iloc[3,:][\"Content\"]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d33087b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26484/3011352920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#for token in tokens:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#    print(token.lemma_, token.pos_, token.tag_, token.dep_,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "doc = nlp(temp)        \n",
    "tokens = [token for token in doc]\n",
    "tokens = [t for t in tokens if t.lemma_ != \"\\n\"]\n",
    "#for token in tokens: \n",
    "#    print(token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#            token.shape_, token.is_alpha, token.is_stop, [child for child in token.children])\n",
    "\n",
    "# tactic: investigate words and follow children until noun is found\n",
    "verbs = [v for v in tokens if v.pos_ == \"VERB\"]\n",
    "\n",
    "def find_noun_children(verb):\n",
    "    level = 0\n",
    "    protocol = []\n",
    "    orig_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "    def iterate_children(verb, level, orig_verb, protocol):\n",
    "        if verb in orig_verb:\n",
    "            add = \"-\"\n",
    "        else:\n",
    "            add = \"#\"\n",
    "        rel_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "        for child in rel_children:\n",
    "            if child.pos_ == \"NOUN\" and child.dep_ != \"npadvmod\":\n",
    "                level = level\n",
    "                protocol.append(child.lemma_+\"[Noun]\")\n",
    "                return protocol\n",
    "            else:\n",
    "                level = level+1\n",
    "                if child.pos_ == \"VERB\":\n",
    "                    protocol.append(child.lemma_)\n",
    "                iterate_children(child, level, orig_verb, protocol)\n",
    "    \n",
    "    res = iterate_children(verb, 0, orig_children, protocol)\n",
    "    return protocol\n",
    "    \n",
    "res = {v: find_noun_children(v) for v in verbs}\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4454df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{thank: ['interest[Noun]', 'application', 'position[Noun]'], application: ['position[Noun]'], reaching: ['lot[Noun]'], doing: ['screen[Noun]', 'assess', 'applicant[Noun]'], assess: ['applicant[Noun]'], allow: ['week[Noun]'], find: ['company[Noun]']}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(temp)        \n",
    "tokens = [token for token in doc]\n",
    "tokens = [t for t in tokens if t.lemma_ != \"\\n\"]\n",
    "#for token in tokens: \n",
    "#    print(token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#            token.shape_, token.is_alpha, token.is_stop, [child for child in token.children])\n",
    "\n",
    "# tactic: investigate words and follow children until noun is found\n",
    "verbs = [v for v in tokens if v.pos_ == \"VERB\"]\n",
    "\n",
    "def find_noun_children(verb):\n",
    "    level = 0\n",
    "    protocol = []\n",
    "    orig_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "    def iterate_children(verb, level, orig_verb, protocol):\n",
    "        if verb in orig_verb:\n",
    "            add = \"-\"\n",
    "        else:\n",
    "            add = \"#\"\n",
    "        rel_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "        for child in rel_children:\n",
    "            if child.pos_ == \"NOUN\" and child.dep_ != \"npadvmod\":\n",
    "                level = level\n",
    "                protocol.append(child.lemma_+\"[Noun]\")\n",
    "                return protocol\n",
    "            else:\n",
    "                level = level+1\n",
    "                if child.pos_ == \"VERB\":\n",
    "                    protocol.append(child.lemma_)\n",
    "                iterate_children(child, level, orig_verb, protocol)\n",
    "    \n",
    "    res = iterate_children(verb, 0, orig_children, protocol)\n",
    "    return protocol\n",
    "    \n",
    "res = {v: find_noun_children(v) for v in verbs}\n",
    "print(res)\n",
    "# Create for each document bag of words - tf-idf, to find out overall topic/activity of email\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f5994",
   "metadata": {},
   "source": [
    "## Textacy Subject-Object-Verb Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6b507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', thank you for your reply and for your kind invitation. The proposed date for a personal meeting works fine for me. I am looking forward to meeting you! '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257c30a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "tuples_list = []          \n",
    "doc = nlp(temp)\n",
    "tuples = textacy.extract.subject_verb_object_triples(doc)\n",
    "if tuples:\n",
    "    tuples_to_list = list(tuples)\n",
    "    tuples_list.append(tuples_to_list)\n",
    "print(tuples_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fd6e3",
   "metadata": {},
   "source": [
    "## Textacy Keyterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221fa0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('personal meeting', 0.07264685846855523),\n",
       " ('kind invitation', 0.06822644776178241),\n",
       " ('fine', 0.03402668454397878),\n",
       " ('date', 0.03360346405887551),\n",
       " ('reply', 0.03340336269097082)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textacy.extract import keyterms as kt\n",
    "kt.textrank(doc)\n",
    "# maybe filter out names and organisations, then check for nouns and verbs here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6c363",
   "metadata": {},
   "source": [
    "## Sentence splitting and extraction of nouns and verbs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9abba094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank, VBP', 'reply, NN', 'invitation, NN']\n",
      "['proposed, VBN', 'date, NN', 'meeting, NN', 'works, VBZ']\n",
      "['looking, VBG', 'meeting, VBG']\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print([f\"{t}, {t.tag_}\" for t in sentence if (t.pos_ == \"VERB\" or t.pos_ == \"NOUN\" and t.dep_ != \"npadvmod\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501225d",
   "metadata": {},
   "source": [
    "## Build Message chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with first message, add next if in-reply-to or sender and (receiver match and date not > 14 days)\n",
    "# convList = []\n",
    "# conv = Conv(from, to, content, headers)\n",
    "# convList.add(conv)\n",
    "# mark added somehow as done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9b56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93ff4e0a",
   "metadata": {},
   "source": [
    "**TODOS**\n",
    "\n",
    "[x] Split end and greeting clause (everything after sincerely, best regards etc. strip)\n",
    "\n",
    "[x] Build dataset\n",
    "\n",
    "Next after Skiing:\n",
    "\n",
    "* Build message chain using Message-ID, receiver/sender info and datetime\n",
    "\n",
    "\n",
    "* Extract verb noun pairs and find way to rank them (e.g., combination of above solutions\n",
    "* Cluster using LDA or similar - all messages to gather super categories, probability of fitting labels\n",
    "* NER for names, skills, positions, activities (application, assess, invite interview, clarify, hire yes/no)\n",
    "* Build cases using similarity measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75ab8328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Height</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Msc</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Princi</td>\n",
       "      <td>6.2</td>\n",
       "      <td>MA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaurav</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Msc</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anuj</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Msc</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Height Qualification  assigned\n",
       "0     Jai     5.1           Msc     False\n",
       "1  Princi     6.2            MA      True\n",
       "2  Gaurav     5.1           Msc     False\n",
       "3    Anuj     5.2           Msc     False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# Define a dictionary containing Students data\n",
    "data = {'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "        'Height': [5.1, 6.2, 5.1, 5.2],\n",
    "        'Qualification': ['Msc', 'MA', 'Msc', 'Msc']}\n",
    " \n",
    "# Convert the dictionary into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    " \n",
    "# Declare a list that is to be converted into a column\n",
    "address = ['Delhi', 'Bangalore', 'Chennai', 'Patna']\n",
    " \n",
    "# Using 'Address' as the column name\n",
    "# and equating it to the list\n",
    "df['assigned'] = False\n",
    "df.loc[1, 'assigned'] = True\n",
    " \n",
    "# Observe the result\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a20d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "d0 = date(2008, 8, 18)\n",
    "d1 = date(2008, 9, 26)\n",
    "delta = d0 - d1\n",
    "print(abs(delta.days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e52242ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "class A(list):    \n",
    "    def pretty(self):\n",
    "        for case in self:\n",
    "            print(case)\n",
    "ob = A()\n",
    "ob.append(\"A\")\n",
    "ob.append(\"B\")\n",
    "ob.pretty()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c5fbc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import dateutil\n",
    "a = datetime.strptime(\"03.05.2017 12:42:00\", '%d.%m.%Y %H:%M:%S')\n",
    "b = datetime.strptime(\"11.05.2017 18:45\", '%d.%m.%Y %H:%M')\n",
    "\n",
    "newDate = dateutil.parser.parse(a)\n",
    "newDate.strftime(\"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "(b-a).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930f133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
