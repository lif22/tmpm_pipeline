{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f8b12be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>In-Reply-To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>office@ziegler-cat.com</td>\n",
       "      <td>01.10.2001  09:15:00</td>\n",
       "      <td>15779.1995312335.JavaMail.evans@thyme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Application for an Internship in Summer 2022</td>\n",
       "      <td>Dear sir or madam,\\n\\nI hereby want to apply f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>05.10.2021  11:01:00</td>\n",
       "      <td>78445.176352.JavaMail@ziegler</td>\n",
       "      <td>15779.1995312335.JavaMail.evans@thyme</td>\n",
       "      <td>Re: Application for an Internship in Summer 2022</td>\n",
       "      <td>Dear Mister Mayer,\\n\\nthank you a lot for your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>12.10.2021  23:11:00</td>\n",
       "      <td>784338.1763212.JavaMail@ziegler</td>\n",
       "      <td>78445.176352.JavaMail@ziegler</td>\n",
       "      <td>Re:Re: Application for an Internship in Summer...</td>\n",
       "      <td>Dear Mister Mayer,\\n\\nthank you for your appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jmayer94@gmail.com</td>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>12.10.2021  08:05:00</td>\n",
       "      <td>127791.19953167485.JavaMail.evans@thyme</td>\n",
       "      <td>784338.1763212.JavaMail@ziegler</td>\n",
       "      <td>Re:Re:Re: Application for an Internship in Sum...</td>\n",
       "      <td>Dear Ms. Parker,\\n\\nthank you for your reply a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.parker@ziegler-cat.com</td>\n",
       "      <td>jmayer94@gmail.com, g.sullenberger@ziegler-cat...</td>\n",
       "      <td>13.10.2021  09:33:00</td>\n",
       "      <td>784971.1786612.JavaMail@ziegler</td>\n",
       "      <td>127791.19953167485.JavaMail.evans@thyme</td>\n",
       "      <td>Invitation for Personal Meeting</td>\n",
       "      <td>Dear Mister Mayer,\\n\\nWe are happy to hear tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       From  \\\n",
       "0        jmayer94@gmail.com   \n",
       "1  j.parker@ziegler-cat.com   \n",
       "2  j.parker@ziegler-cat.com   \n",
       "3        jmayer94@gmail.com   \n",
       "4  j.parker@ziegler-cat.com   \n",
       "\n",
       "                                                  To              Datetime  \\\n",
       "0                             office@ziegler-cat.com  01.10.2001  09:15:00   \n",
       "1                                 jmayer94@gmail.com  05.10.2021  11:01:00   \n",
       "2                                 jmayer94@gmail.com  12.10.2021  23:11:00   \n",
       "3                           j.parker@ziegler-cat.com  12.10.2021  08:05:00   \n",
       "4  jmayer94@gmail.com, g.sullenberger@ziegler-cat...  13.10.2021  09:33:00   \n",
       "\n",
       "                                Message-ID  \\\n",
       "0    15779.1995312335.JavaMail.evans@thyme   \n",
       "1            78445.176352.JavaMail@ziegler   \n",
       "2          784338.1763212.JavaMail@ziegler   \n",
       "3  127791.19953167485.JavaMail.evans@thyme   \n",
       "4          784971.1786612.JavaMail@ziegler   \n",
       "\n",
       "                               In-Reply-To  \\\n",
       "0                                      NaN   \n",
       "1    15779.1995312335.JavaMail.evans@thyme   \n",
       "2            78445.176352.JavaMail@ziegler   \n",
       "3          784338.1763212.JavaMail@ziegler   \n",
       "4  127791.19953167485.JavaMail.evans@thyme   \n",
       "\n",
       "                                             Subject  \\\n",
       "0       Application for an Internship in Summer 2022   \n",
       "1   Re: Application for an Internship in Summer 2022   \n",
       "2  Re:Re: Application for an Internship in Summer...   \n",
       "3  Re:Re:Re: Application for an Internship in Sum...   \n",
       "4                    Invitation for Personal Meeting   \n",
       "\n",
       "                                             Content  \n",
       "0  Dear sir or madam,\\n\\nI hereby want to apply f...  \n",
       "1  Dear Mister Mayer,\\n\\nthank you a lot for your...  \n",
       "2  Dear Mister Mayer,\\n\\nthank you for your appli...  \n",
       "3  Dear Ms. Parker,\\n\\nthank you for your reply a...  \n",
       "4  Dear Mister Mayer,\\n\\nWe are happy to hear tha...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the main executablefile of the process mining pipeline\n",
    "# Author: Florian Lietz\n",
    "# Last edited\n",
    "# \n",
    "\n",
    "import os, sys, re\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "from stages.utils.utils import parseArgs, DataCleaner\n",
    "import spacy\n",
    "f = r\"C:\\Users\\flietz\\OneDrive - TU Wien\\!Studium\\1_MSc\\!Diplomarbeit\\code\\pipeline\\resources\\dataset\\Mail_ApplicationDummy.csv\"\n",
    "# import CSV file\n",
    "inputFile = pd.read_csv(f, delimiter=\";\")\n",
    "inputFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6db7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUrl(content):\n",
    "    return re.sub(r'https?://\\S+', '', content)\n",
    "\n",
    "def removeMultWhitespace(content):\n",
    "    return re.sub(r' +', ' ', content)\n",
    "\n",
    "def stripEndClauses(content, clauses):\n",
    "    clauseIndex = 0\n",
    "    index = 0\n",
    "    # Find lowest greetings or end clause index and strip off everything that comes after it\n",
    "    for item in clauses:\n",
    "        # needle and haystack both in lowercase to ignore case\n",
    "        index = content.lower().find(item.lower())\n",
    "        if index > -1 and (index < clauseIndex or clauseIndex == 0):\n",
    "            clauseIndex = index\n",
    "    if clauseIndex > 0:\n",
    "        return content[:clauseIndex]\n",
    "    else:\n",
    "        return content\n",
    "\n",
    "def stripStartClauses(content, clauses):\n",
    "    clauseIndex = 0\n",
    "    index = 0\n",
    "    # Find lowest greetings or end clause index and strip off everything that comes after it\n",
    "    for item in clauses:\n",
    "        # needle and haystack both in lowercase to ignore case\n",
    "        index = content.lower().find(item.lower())\n",
    "        if index > -1 and (index > clauseIndex or clauseIndex == 0):\n",
    "            clauseIndex = index\n",
    "    if clauseIndex > 0:\n",
    "        return content[clauseIndex:]\n",
    "    else:\n",
    "        return content\n",
    "    \n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: removeMultWhitespace(row[\"Content\"]), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: removeUrl(row[\"Content\"]), axis=1)\n",
    "\n",
    "# Stripping of greeting phrases and end clauses\n",
    "startClausesList = [\"Dear sir or madam\", \"To whom it may concern\", \"Hello,\", \",\\n\\n\"]\n",
    "\n",
    "endGreetingsList = [\"Yours sincerely\", \"Sincerely\", \"Sincerely yours\", \"Take care\", \"Regards\",\n",
    "                 \"Warm regards\", \"Best regards\", \"Kind regards\", \"Warmest regards\", \"Yours truly\", \"Yours,\",\n",
    "                 \"Warmly,\", \"Warm wishes\", \"Best,\", \"Best Wishes\", \"Thanks in advance\", \"Thank you in advance\",\n",
    "                 \"Thanks in advance\", \"Thanks,\\n\", \"I am looking forward to hearing\", \"I'm looking forward to hearing\",\n",
    "                 \"I look forward to hearing from you\"]\n",
    "\n",
    "confList = [\"The information contained in this communication\",\n",
    "               \"The content of this email is confidential\", \"The content of this e-mail\", \"This email and attachments (if any) is intended\",\n",
    "               \"This email is intended solely\", \"This e-mail is intended\"]\n",
    "\n",
    "endClausesList = endGreetingsList+confList\n",
    "\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: stripEndClauses(row[\"Content\"], endClausesList), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: stripStartClauses(row[\"Content\"], startClausesList), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: re.sub(r'\\n+', '\\n', row[\"Content\"]), axis=1)\n",
    "inputFile[\"Content\"] = inputFile.apply(lambda row: re.sub(r'\\n', ' ', row[\"Content\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea29ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b89a6fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     , I hereby want to apply for the internship po...\n",
       "1     , thank you a lot for your interest in Ziegler...\n",
       "2     , thank you for your application and your wait...\n",
       "3     , thank you for your reply and for your kind i...\n",
       "4     , We are happy to hear that. My assistant will...\n",
       "5     , it was a pleasure to meet you in person and ...\n",
       "6     , Thank you a lot for your interest in our com...\n",
       "7     , After having screened your application, unfo...\n",
       "8     , I hereby want to apply for the position of \"...\n",
       "9     , thank you a lot for your appliation which ha...\n",
       "10    , thank you a lot for your application at Lind...\n",
       "11    , please find attached the missing transcript....\n",
       "12    Dear Ms. Bender, thank you for the document. T...\n",
       "13    , After having assessed your application docum...\n",
       "14    , thank you for your consideration and the inv...\n",
       "15    , It was a pleasure to meet you in person. We ...\n",
       "16    Dear Ms Hoeller, thank you for your email and ...\n",
       "17    Dear Ms. Bender, thank you for you reply. For ...\n",
       "18    , After consultations, we want to offer you a ...\n",
       "19    Dear Ms. Hoeller, thank you a lot for the revi...\n",
       "20    , we are happy to have you on board. As specif...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = inputFile[\"Content\"]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d33087b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E866] Expected a string or 'Doc' as input, but got: <class 'pandas.core.series.Series'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26484/3011352920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#for token in tokens:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#    print(token.lemma_, token.pos_, token.tag_, token.dep_,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\da\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    999\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;31m#call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \"\"\"\n\u001b[1;32m-> 1001\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\da\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m_ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE866\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_doc_with_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_like\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E866] Expected a string or 'Doc' as input, but got: <class 'pandas.core.series.Series'>."
     ]
    }
   ],
   "source": [
    "doc = nlp(temp)        \n",
    "tokens = [token for token in doc]\n",
    "tokens = [t for t in tokens if t.lemma_ != \"\\n\"]\n",
    "#for token in tokens: \n",
    "#    print(token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#            token.shape_, token.is_alpha, token.is_stop, [child for child in token.children])\n",
    "\n",
    "# tactic: investigate words and follow children until noun is found\n",
    "verbs = [v for v in tokens if v.pos_ == \"VERB\"]\n",
    "\n",
    "def find_noun_children(verb):\n",
    "    level = 0\n",
    "    protocol = []\n",
    "    orig_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "    def iterate_children(verb, level, orig_verb, protocol):\n",
    "        if verb in orig_verb:\n",
    "            add = \"-\"\n",
    "        else:\n",
    "            add = \"#\"\n",
    "        rel_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "        for child in rel_children:\n",
    "            if child.pos_ == \"NOUN\" and child.dep_ != \"npadvmod\":\n",
    "                level = level\n",
    "                protocol.append(child.lemma_+\"[Noun]\")\n",
    "                return protocol\n",
    "            else:\n",
    "                level = level+1\n",
    "                if child.pos_ == \"VERB\":\n",
    "                    protocol.append(child.lemma_)\n",
    "                iterate_children(child, level, orig_verb, protocol)\n",
    "    \n",
    "    res = iterate_children(verb, 0, orig_children, protocol)\n",
    "    return protocol\n",
    "    \n",
    "res = {v: find_noun_children(v) for v in verbs}\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4454df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{thank: ['interest[Noun]', 'application', 'position[Noun]'], application: ['position[Noun]'], reaching: ['lot[Noun]'], doing: ['screen[Noun]', 'assess', 'applicant[Noun]'], assess: ['applicant[Noun]'], allow: ['week[Noun]'], find: ['company[Noun]']}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(temp)        \n",
    "tokens = [token for token in doc]\n",
    "tokens = [t for t in tokens if t.lemma_ != \"\\n\"]\n",
    "#for token in tokens: \n",
    "#    print(token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#            token.shape_, token.is_alpha, token.is_stop, [child for child in token.children])\n",
    "\n",
    "# tactic: investigate words and follow children until noun is found\n",
    "verbs = [v for v in tokens if v.pos_ == \"VERB\"]\n",
    "\n",
    "def find_noun_children(verb):\n",
    "    level = 0\n",
    "    protocol = []\n",
    "    orig_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "    def iterate_children(verb, level, orig_verb, protocol):\n",
    "        if verb in orig_verb:\n",
    "            add = \"-\"\n",
    "        else:\n",
    "            add = \"#\"\n",
    "        rel_children = [c for c in verb.children if c.pos_ != \"PUNCT\" and c.pos_ != \"SPACE\"]\n",
    "        for child in rel_children:\n",
    "            if child.pos_ == \"NOUN\" and child.dep_ != \"npadvmod\":\n",
    "                level = level\n",
    "                protocol.append(child.lemma_+\"[Noun]\")\n",
    "                return protocol\n",
    "            else:\n",
    "                level = level+1\n",
    "                if child.pos_ == \"VERB\":\n",
    "                    protocol.append(child.lemma_)\n",
    "                iterate_children(child, level, orig_verb, protocol)\n",
    "    \n",
    "    res = iterate_children(verb, 0, orig_children, protocol)\n",
    "    return protocol\n",
    "    \n",
    "res = {v: find_noun_children(v) for v in verbs}\n",
    "print(res)\n",
    "# Create for each document bag of words - tf-idf, to find out overall topic/activity of email\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f5994",
   "metadata": {},
   "source": [
    "## Textacy Subject-Object-Verb Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce6b507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     , I hereby want to apply for the internship po...\n",
       "1     , thank you a lot for your interest in Ziegler...\n",
       "2     , thank you for your application and your wait...\n",
       "3     , thank you for your reply and for your kind i...\n",
       "4     , We are happy to hear that. My assistant will...\n",
       "5     , it was a pleasure to meet you in person and ...\n",
       "6     , Thank you a lot for your interest in our com...\n",
       "7     , After having screened your application, unfo...\n",
       "8     , I hereby want to apply for the position of \"...\n",
       "9     , thank you a lot for your appliation which ha...\n",
       "10    , thank you a lot for your application at Lind...\n",
       "11    , please find attached the missing transcript....\n",
       "12    Dear Ms. Bender, thank you for the document. T...\n",
       "13    , After having assessed your application docum...\n",
       "14    , thank you for your consideration and the inv...\n",
       "15    , It was a pleasure to meet you in person. We ...\n",
       "16    Dear Ms Hoeller, thank you for your email and ...\n",
       "17    Dear Ms. Bender, thank you for you reply. For ...\n",
       "18    , After consultations, we want to offer you a ...\n",
       "19    Dear Ms. Hoeller, thank you a lot for the revi...\n",
       "20    , we are happy to have you on board. As specif...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "257c30a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E866] Expected a string or 'Doc' as input, but got: <class 'pandas.core.series.Series'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26484/1729775565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtuples_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtuples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubject_verb_object_triples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\da\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    999\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;31m#call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \"\"\"\n\u001b[1;32m-> 1001\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\da\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m_ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE866\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_doc_with_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_like\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E866] Expected a string or 'Doc' as input, but got: <class 'pandas.core.series.Series'>."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "tuples_list = []          \n",
    "doc = nlp(temp)\n",
    "tuples = textacy.extract.subject_verb_object_triples(doc)\n",
    "if tuples:\n",
    "    tuples_to_list = list(tuples)\n",
    "    tuples_list.append(tuples_to_list)\n",
    "print(tuples_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fd6e3",
   "metadata": {},
   "source": [
    "## Textacy Keyterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "221fa0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('personal meeting', 0.07264685846855523),\n",
       " ('kind invitation', 0.06822644776178241),\n",
       " ('fine', 0.03402668454397878),\n",
       " ('date', 0.03360346405887551),\n",
       " ('reply', 0.03340336269097082)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textacy.extract import keyterms as kt\n",
    "kt.textrank(doc)\n",
    "# maybe filter out names and organisations, then check for nouns and verbs here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6c363",
   "metadata": {},
   "source": [
    "## Sentence splitting and extraction of nouns and verbs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9abba094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank, VBP', 'reply, NN', 'invitation, NN']\n",
      "['proposed, VBN', 'date, NN', 'meeting, NN', 'works, VBZ']\n",
      "['looking, VBG', 'meeting, VBG']\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print([f\"{t}, {t.tag_}\" for t in sentence if (t.pos_ == \"VERB\" or t.pos_ == \"NOUN\" and t.dep_ != \"npadvmod\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b66799",
   "metadata": {},
   "source": [
    "## Build Message chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with first message, add next if in-reply-to or sender and (receiver match and date not > 14 days)\n",
    "# convList = []\n",
    "# conv = Conv(from, to, content, headers)\n",
    "# convList.add(conv)\n",
    "# mark added somehow as done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041f17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93ff4e0a",
   "metadata": {},
   "source": [
    "**TODOS**\n",
    "\n",
    "[x] Split end and greeting clause (everything after sincerely, best regards etc. strip)\n",
    "\n",
    "[x] Build dataset\n",
    "\n",
    "Next after Skiing:\n",
    "\n",
    "* Build message chain using Message-ID, receiver/sender info and datetime\n",
    "\n",
    "\n",
    "* Extract verb noun pairs and find way to rank them (e.g., combination of above solutions\n",
    "* Cluster using LDA or similar - all messages to gather super categories, probability of fitting labels\n",
    "* NER for names, skills, positions, activities (application, assess, invite interview, clarify, hire yes/no)\n",
    "* Build cases using similarity measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dd44a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"\"\n",
    "a+=\"b\"\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e9180bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H <-\n",
      "a <-\n",
      "l <-\n",
      "l <-\n",
      "o <-\n",
      ", <-\n",
      "  <-\n",
      "w <-\n",
      "i <-\n",
      "e <-\n",
      "  <-\n",
      "g <-\n",
      "e <-\n",
      "h <-\n",
      "t <-\n",
      "s <-\n"
     ]
    }
   ],
   "source": [
    "a = \"Hallo, wie gehts\"\n",
    "for word in a:\n",
    "    print(f\"{word} <-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161ccec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
